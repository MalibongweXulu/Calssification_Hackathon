{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used for this challenge is the NCHLT Text Corpora collected by the South African Department of Arts and Culture & Centre for Text Technology (CTexT, North-West University, South Africa). The training set was improved through additional cleaning done by Praekelt.\n",
    "\n",
    "The data is in the form Language ID, Text. The text is in various states of cleanliness. Some NLP techniques will be necessary to clean up the data.\n",
    "\n",
    "\n",
    "**File descriptions**\n",
    "\n",
    "train_set.csv - the training set\n",
    "\n",
    "test_set.csv - the test set\n",
    "\n",
    "sample_submission.csv - a sample submission file in the correct format\n",
    "\n",
    "\n",
    "**Language IDs**\n",
    "\n",
    "afr - Afrikaans\n",
    "\n",
    "eng - English\n",
    "\n",
    "nbl - isiNdebele\n",
    "\n",
    "nso - Sepedi\n",
    "\n",
    "sot - Sesotho\n",
    "\n",
    "ssw - siSwati\n",
    "\n",
    "tsn - Setswana\n",
    "\n",
    "tso - Xitsonga\n",
    "\n",
    "ven - Tshivenda\n",
    "\n",
    "xho - isiXhosa\n",
    "\n",
    "zul - isiZulu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_set.csv')\n",
    "test = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data  preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport spacy\\nfrom spacy.lang.en.stop_words import STOP_WORDS\\n\\n#loading the en_core_web_sm_model\\nstopwords = STOP_WORDS\\nnlp = spacy.load('en_core_web_sm')\\n\\n\\ndef preprocess(train):\\n    #creating a Doc object\\n    doc = nlp(train, disable = ['ner', 'parser'])\\n    #Generating lemmas\\n    lemmas = [token.lemma_ for token in doc]\\n    #remove stopwords and non-alphabetic characters\\n    a_lemma = [lemma for lemma in lemmas\\n              if lemma.isalpha() and lemma not in stopwords ]\\n    return ' ' .join(a_lemma)\\n\\n#apply preprocessing to posts\\ntrain['text_new']= train['text'].apply(preprocess)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "#loading the en_core_web_sm_model\n",
    "stopwords = STOP_WORDS\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def preprocess(train):\n",
    "    #creating a Doc object\n",
    "    doc = nlp(train, disable = ['ner', 'parser'])\n",
    "    #Generating lemmas\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    #remove stopwords and non-alphabetic characters\n",
    "    a_lemma = [lemma for lemma in lemmas\n",
    "              if lemma.isalpha() and lemma not in stopwords ]\n",
    "    return ' ' .join(a_lemma)\n",
    "\n",
    "#apply preprocessing to posts\n",
    "train['text_new']= train['text'].apply(preprocess)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tso    3000\n",
       "tsn    3000\n",
       "nbl    3000\n",
       "eng    3000\n",
       "xho    3000\n",
       "afr    3000\n",
       "ssw    3000\n",
       "nso    3000\n",
       "zul    3000\n",
       "sot    3000\n",
       "ven    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.lang_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate features and tagret variables\n",
    "y = train['lang_id']\n",
    "X = train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2, stop_words=\"english\")\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train data to create validation dataset\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.3,shuffle=True, stratify=y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rfc = RandomForestClassifier(max_features=4, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9964655269584973"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, rfc_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = test['text']\n",
    "test_vect = vectorizer.transform(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lang_id'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "      <td>ven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text lang_id\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...     ssw\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...     nbl\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.     ven\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...     ssw\n",
       "4      5                      Winste op buitelandse valuta.     ssw"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['index','lang_id']].to_csv('test_rfc_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1.0, max_depth=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Gradient Boosting Classifier\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1)\n",
    "\n",
    "gb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[881   0  19   0   0   0   0   0   0   0   0]\n",
      " [  3 829  68   0   0   0   0   0   0   0   0]\n",
      " [  1   1 799   8   0  35   2   3   0  36  15]\n",
      " [  0   0  14 860   1   0  25   0   0   0   0]\n",
      " [  0   0  14  35 833   0  17   1   0   0   0]\n",
      " [  0   7 392   2   0 478   0   4   3   0  14]\n",
      " [  0   3  16  49   1   0 831   0   0   0   0]\n",
      " [  0   0   5   5   1   0   2 873  14   0   0]\n",
      " [  0   0  12   0  12   0   4   1 871   0   0]\n",
      " [  0   5 165   4   0   0   0   1   0 715  10]\n",
      " [  0   6 416   6   0   8   0   3   0  22 439]]\n"
     ]
    }
   ],
   "source": [
    "# Create a prediction set:\n",
    "pred_gb = gb_model.predict(X_val)\n",
    "\n",
    "# Print a confusion matrix for NB Model\n",
    "print(metrics.confusion_matrix(y_val,pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8567063173542224"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, pred_gb, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the test data to test the Gradient Boosting model\n",
    "test_gb = test['text']\n",
    "test_vect_gb = vectorizer.transform(test_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment using the test data\n",
    "y_pred_gb = gb_model.predict(test_vect_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a new column on the test data by using the predicted sentiment from the tweets from test data\n",
    "test['lang_id'] = y_pred_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the csv file and submit it. \n",
    "test[['index','lang_id']].to_csv('test_gb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lsvc = LinearSVC()\n",
    "#print(lsvc)\n",
    "\n",
    "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "          verbose=0)\n",
    "\n",
    "# fit the model on train data and check the model accuracy score.\n",
    "lsvc.fit(X_train, y_train)\n",
    "score = lsvc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply a cross-validation training method to the model and check the training score.\n",
    "cv_scores = cross_val_score(lsvc, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#Now, we can predict the test data by using the trained model. After the prediction, we'll check the accuracy level by using the confusion matrix functionfrom sklearn.metrics import confusion_matrix\n",
    "\n",
    "ypred = lsvc.predict(X_val)\n",
    "\n",
    "cm = confusion_matrix(y_val, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       900\n",
      "         eng       1.00      1.00      1.00       900\n",
      "         nbl       0.99      0.99      0.99       900\n",
      "         nso       1.00      1.00      1.00       900\n",
      "         sot       1.00      1.00      1.00       900\n",
      "         ssw       1.00      1.00      1.00       900\n",
      "         tsn       1.00      1.00      1.00       900\n",
      "         tso       1.00      1.00      1.00       900\n",
      "         ven       1.00      1.00      1.00       900\n",
      "         xho       1.00      1.00      1.00       900\n",
      "         zul       0.99      0.99      0.99       900\n",
      "\n",
      "    accuracy                           1.00      9900\n",
      "   macro avg       1.00      1.00      1.00      9900\n",
      "weighted avg       1.00      1.00      1.00      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We can also create a classification report by using classification_report() function on predicted data to check the other accuracy metrics\n",
    "#Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the test data to test the lsv model\n",
    "test_lsv = test['text']\n",
    "test_vecto = vectorizer.transform(test_lsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment using the test data\n",
    "y_pred_lsv = lsvc.predict(test_vecto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lang_id'] = y_pred_lsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the csv file and submit it. \n",
    "test[['index','lang_id']].to_csv('test_lsv2_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988888888888889\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_val)\n",
    "\n",
    "print(np.mean(predicted == y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[900   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 900   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0 896   0   0   0   0   0   0   0   3]\n",
      " [  0   0   0 900   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 900   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 900   0   0   0   0   0]\n",
      " [  1   0   0   1   0   0 898   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 900   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 900   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0 898   1]\n",
      " [  0   2   1   0   0   0   0   0   0   0 897]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_val, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the csv file and submit it. \n",
    "test[['index','lang_id']].to_csv('test_mnb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(max_iter=5000, tol=0.01)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(max_iter=5000, tol=0.01)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the classifier by using the SGDClassifier class. Then fit it on the train data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdc = SGDClassifier(max_iter=5000, tol=0.01)\n",
    "print(sgdc)\n",
    " \n",
    "sgdc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9998268398268398\n"
     ]
    }
   ],
   "source": [
    "#After the training the classifier, we'll check the model accuracy score\n",
    "score = sgdc.score(X_train, y_train)\n",
    "print(\"Training score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[900   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 900   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0 888   0   0   0   0   0   0   2   9]\n",
      " [  0   0   0 898   0   0   2   0   0   0   0]\n",
      " [  0   0   0   1 899   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 897   0   0   0   0   3]\n",
      " [  1   0   0   0   0   0 899   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 900   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 900   0   0]\n",
      " [  0   2   1   0   0   0   0   0   0 896   1]\n",
      " [  0   1   6   0   0   1   0   0   0   5 887]]\n"
     ]
    }
   ],
   "source": [
    "# Now, we can predict the test data by using the trained model. After the prediction, we'll check the accuracy level by using the confusion matrix function\n",
    "\n",
    "ypred = sgdc.predict(X_val)\n",
    "\n",
    "cm = confusion_matrix(y_val, ypred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       900\n",
      "         eng       1.00      1.00      1.00       900\n",
      "         nbl       0.99      0.99      0.99       900\n",
      "         nso       1.00      1.00      1.00       900\n",
      "         sot       1.00      1.00      1.00       900\n",
      "         ssw       1.00      1.00      1.00       900\n",
      "         tsn       1.00      1.00      1.00       900\n",
      "         tso       1.00      1.00      1.00       900\n",
      "         ven       1.00      1.00      1.00       900\n",
      "         xho       0.99      1.00      0.99       900\n",
      "         zul       0.99      0.99      0.99       900\n",
      "\n",
      "    accuracy                           1.00      9900\n",
      "   macro avg       1.00      1.00      1.00      9900\n",
      "weighted avg       1.00      1.00      1.00      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We can also create a classification report by using classification_report() function on predicted data to check the other accuracy metrics.\n",
    "\n",
    "cr = classification_report(y_val, ypred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sgdc = test['text']\n",
    "test_vector = vectorizer.transform(test_sgdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment using the test data\n",
    "y_pred_sgdc = sgdc.predict(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lang_id'] = y_pred_sgdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the csv file and submit it. \n",
    "test[['index','lang_id']].to_csv('test_sgdc_submission5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier(n_neighbors = 4)\n",
    "print(knc)\n",
    " \n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
    "                     weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9824675324675325\n"
     ]
    }
   ],
   "source": [
    "#We'll fit the model on the train data. After the training the classifier, we'll check the model accuracy score.\n",
    "\n",
    "knc.fit(X_train, y_train)\n",
    " \n",
    "score = knc.score(X_train, y_train)\n",
    "print(\"Training score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[899   0   0   0   1   0   0   0   0   0   0]\n",
      " [  2 896   0   0   0   2   0   0   0   0   0]\n",
      " [  4   5 853   0   0   3   0   0   0  10  25]\n",
      " [  1   1   0 880   8   0  10   0   0   0   0]\n",
      " [  1   1   0  16 875   0   7   0   0   0   0]\n",
      " [  0   9   9   0   0 869   0   0   0   4   9]\n",
      " [  3   1   0  30  38   0 827   0   0   0   1]\n",
      " [  0   0   0   0   1   0   0 899   0   0   0]\n",
      " [  0   1   3   1   0   2   0   0 893   0   0]\n",
      " [  1   7  21   0   1   2   0   2   0 852  14]\n",
      " [  0  11  43   0   0  22   2   1   1  43 777]]\n"
     ]
    }
   ],
   "source": [
    "# Now, we can predict the test data by using the trained model. After the prediction, we'll check the accuracy level by using the confusion matrix function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ypred = knc.predict(X_val)\n",
    "\n",
    "cm = confusion_matrix(y_val, ypred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       0.99      1.00      0.99       900\n",
      "         eng       0.96      1.00      0.98       900\n",
      "         nbl       0.92      0.95      0.93       900\n",
      "         nso       0.95      0.98      0.96       900\n",
      "         sot       0.95      0.97      0.96       900\n",
      "         ssw       0.97      0.97      0.97       900\n",
      "         tsn       0.98      0.92      0.95       900\n",
      "         tso       1.00      1.00      1.00       900\n",
      "         ven       1.00      0.99      1.00       900\n",
      "         xho       0.94      0.95      0.94       900\n",
      "         zul       0.94      0.86      0.90       900\n",
      "\n",
      "    accuracy                           0.96      9900\n",
      "   macro avg       0.96      0.96      0.96      9900\n",
      "weighted avg       0.96      0.96      0.96      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We can also create a classification report by using classification_report() function on predicted data to check the other accuracy metrics\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(y_val, ypred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_knc = test['text']\n",
    "test_vector = vectorizer.transform(test_knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knc = knc.predict(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lang_id'] = y_pred_knc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['index','lang_id']].to_csv('test_knc_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
